{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a2b08e4-9ece-4d0b-8578-665be3245fdb",
   "metadata": {},
   "source": [
    "**First, we will read the unseen data and split the label 'charges' from the features (y_test and X_test).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b5f74d-d6f8-41e1-b0aa-85acc5f84a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('real-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339dee08-a47f-40b0-b87e-161ab96cb9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = data['charges'].copy()\n",
    "X_test = data.drop('charges', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a767da-a890-4950-88de-c70a2001ad88",
   "metadata": {},
   "source": [
    "**Before testing our model on the unseen data, we must load our saved model as well as our preprocessing functions.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "988c740a-4b9f-401a-b131-d13f59de4056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# loading the preprocessing objects into the 'scaler.pkl' file.\n",
    "\n",
    "with open('imputer.pkl', 'rb') as f:\n",
    "    imputer = pickle.load(f)\n",
    "\n",
    "with open('scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "with open('one_hot_encoder.pkl', 'rb') as f:\n",
    "    one_hot_encoder = pickle.load(f)\n",
    "\n",
    "with open('imp_neg_mode.pkl', 'rb') as f:\n",
    "    imp_neg_mode = pickle.load(f)\n",
    "\n",
    "with open('imp_region_mode.pkl', 'rb') as f:\n",
    "    imp_region_mode = pickle.load(f)\n",
    "\n",
    "with open('imp_typos_mode.pkl', 'rb') as f:\n",
    "    imp_typos_mode = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "842f971b-fc9b-4f94-b734-8fdd08e2d468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 100)               1200      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               12928     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24497 (95.69 KB)\n",
      "Trainable params: 24497 (95.69 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Loading our chosen model\n",
    "model5 = load_model('trained_model.keras')\n",
    "\n",
    "model5.summary()  # to confirm we have saved and loaded the correct/chosen model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e59c2-c902-4c20-bc4b-f4e321cabab9",
   "metadata": {},
   "source": [
    "**We must now make the unseen test data undergo the same preprocessing as the data we were given to train the model with. Since we are assuming that the unseen data can have any of the issues the given dataset had, we will address those issues. However, we will NOT retrain the functions used (like scalers, imputers, and encoders). To ensure fairness in our judgement of the model's predictions, we will use the same functions as they were.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40975334-623e-4b82-ae60-9db4a10d74d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "  \n",
    "# Function to preprocess testing data\n",
    "def preprocessing_testing(unseen_data, imp_neg_mode, imp_region_mode, imp_typos_mode, imputer, scaler, one_hot_encoder):\n",
    "    import numpy as np\n",
    "    \n",
    "    ################################# Handling 'age' & 'children' Outliers #########################################\n",
    "\n",
    "    unseen_data['age'] = unseen_data['age'].abs()\n",
    "    # replace all negative values in children by np.nan (instead of None to keep it numerical)\n",
    "    unseen_data.loc[unseen_data['children'] < 0, 'children'] = np.nan\n",
    "    # next we can impute the np.nan with the mode number of children\n",
    "    unseen_data[['children']] = imp_neg_mode.transform(unseen_data[['children']])\n",
    "\n",
    "    ################################# Mode-Imputing 'region' Missing Values ##########################################\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    #imp_region_mode = SimpleImputer(missing_values=np.nan, strategy='most_frequent') \n",
    "    unseen_data[['region']] = imp_region_mode.transform(unseen_data[['region']])\n",
    "\n",
    "    ###################################### Mode-Imputing 'sex' Typos #################################################\n",
    "\n",
    "    # first we replace instances of the two typos with None\n",
    "    unseen_data.loc[unseen_data['sex'] == 'dasdas', 'sex'] = None\n",
    "    unseen_data.loc[unseen_data['sex'] == 'wqeqwrf', 'sex'] = None\n",
    "    \n",
    "    # next we can impute the None with the mode \n",
    "    #imp_typos_mode = SimpleImputer(missing_values=None, strategy='most_frequent') \n",
    "    unseen_data[['sex']] = imp_typos_mode.transform(unseen_data[['sex']])\n",
    "\n",
    "    # Separate numerical and categorical columns\n",
    "    numerical_cols = unseen_data.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "    categorical_cols = unseen_data.select_dtypes(include=[\"object\"]).columns\n",
    "    \n",
    "    ############################################### Data Cleaning #################################################\n",
    "    # Impute missing values for numerical data using the imputer from training\n",
    "    unseen_data[numerical_cols] = imputer.transform(unseen_data[numerical_cols])\n",
    "    \n",
    "    ############################################## Feature Scaling ################################################\n",
    "    # Scale numerical features using the scaler from training\n",
    "    unseen_data[numerical_cols] = scaler.transform(unseen_data[numerical_cols])\n",
    "    \n",
    "    ############################################ Categorization ###################################################\n",
    "    # One-hot encode categorical features using the encoder from training\n",
    "    encoded_categorical = one_hot_encoder.transform(unseen_data[categorical_cols])\n",
    "    encoded_df = pd.DataFrame(\n",
    "        encoded_categorical, \n",
    "        columns=one_hot_encoder.get_feature_names_out(categorical_cols),\n",
    "        index=unseen_data.index\n",
    "    )\n",
    "    \n",
    "    # Combine original data with encoded data\n",
    "    df_encoded = pd.concat([unseen_data.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "    return df_encoded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d45d335-9674-4ac9-88b9-6a98beafa285",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_transformed = preprocessing_testing(X_test, imp_neg_mode, imp_region_mode, imp_typos_mode, imputer, scaler, one_hot_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5438dae-86e5-4ff2-9686-7524b5c68243",
   "metadata": {},
   "source": [
    "**Using our model to predict the charges of the unseen data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42b3516-8499-48de-902a-614da3302b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model5.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2356ccb-9b82-49b5-801a-f08e68eaf734",
   "metadata": {},
   "source": [
    "**Comparing our model's predictions to the actual charges then evaluating its performance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3dff2d-e482-4f7a-9ef3-1e2e6c5b6c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model3.compile(optimizer='rmsprop', loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "test_loss, test_mae = model5.evaluate(X_test_transformed, y_test)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE) on the test set: {test_mae:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52162f1-d053-4821-8bca-96c101116486",
   "metadata": {},
   "outputs": [],
   "source": [
    "for actual,pred in zip(y_test[:5], predictions[:5]):\n",
    "    print(f'Actual: {actual}, pred: {pred}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
